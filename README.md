
## Prerequisites

1. Make sure the Ollama or llama.cpp local deployment is done.

2. Create conda environment by `conda env create --file environment.yml`
